{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기출문제 6회 문제 - 1유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 1. \n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/data_6_1_1.csv')\n",
    "df['출동시간'] = pd.to_datetime(df['출동시간'])\n",
    "df['도착시간'] = pd.to_datetime(df['도착시간'])\n",
    "\n",
    "df['duration'] = (df['도착시간'] - df['출동시간']).dt.total_seconds() / 60\n",
    "df.groupby('구급대')['duration'].mean().reset_index(name = 'time').sort_values(by = 'time', ascending = False)\n",
    "\n",
    "# Answer: 83\n",
    "\n",
    "# 2. \n",
    "df = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/data_6_1_2.csv')\n",
    "df['temp'] = df.apply(lambda x: (x['경영학과'] + x['경제학과'] + x['컴퓨터공학과'] + x['산업공학과'] + x['국문학과'] + x['영문학과']) / x['교수'], axis = 1)\n",
    "df.iloc[:, 2:].sum(axis = 1)\n",
    "df.sort_values('temp', ascending = False)\n",
    "\n",
    "# Answer: 22\n",
    "\n",
    "# 3. \n",
    "df = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/data_6_1_3.csv')\n",
    "df['year'] = df['날짜'].apply(lambda x: x[:4])\n",
    "df['month'] = df['날짜'].apply(lambda x: x[6:8])\n",
    "\n",
    "df.groupby('year').apply(lambda x: (x['폭력범죄'] + x['지능범죄'] + x['교통범죄'] + x['절도범죄'] + x['경제범죄'] + x['정치범죄']).sum())\n",
    "# 2018    6328\n",
    "# 2019    6246\n",
    "# 2020    6179\n",
    "# 2021    6340\n",
    "# 2022    6293\n",
    "\n",
    "df1 = df[df['year'] == '2021']\n",
    "(df1['폭력범죄'] + df1['지능범죄'] + df1['교통범죄'] + df1['절도범죄'] + df1['경제범죄'] + df1['정치범죄']).sum() / 12\n",
    "\n",
    "# Answer: 528\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기출문제 6회 문제 - 2유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jina/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "/Users/jina/Library/Python/3.9/lib/python/site-packages/sklearn/preprocessing/_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "/Users/jina/Library/Python/3.9/lib/python/site-packages/sklearn/base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return fit_method(estimator, *args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# 1. \n",
    "\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/data_6_2_train.csv')\n",
    "df_test = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/data_6_2_test.csv')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "# scaler\n",
    "scaler = StandardScaler()\n",
    "df['일평균수면시간'] = scaler.fit_transform(df[['일평균수면시간']])\n",
    "df_test['일평균수면시간'] = scaler.transform(df_test[['일평균수면시간']])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df['일평균학습시간'] = scaler.fit_transform(df[['일평균학습시간']])\n",
    "df_test['일평균학습시간'] = scaler.transform(df_test[['일평균학습시간']])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df['일평균스마트폰사용시간'] = scaler.fit_transform(df[['일평균스마트폰사용시간']])\n",
    "df_test['일평균스마트폰사용시간'] = scaler.transform(df_test[['일평균스마트폰사용시간']])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "df['몸무게'] = scaler.fit_transform(df[['몸무게']])\n",
    "df_test['몸무게'] = scaler.transform(df_test[['몸무게']])\n",
    "                                  \n",
    "scaler = StandardScaler()\n",
    "df['기초대사량'] = scaler.fit_transform(df[['기초대사량']])\n",
    "df_test['기초대사량'] = scaler.transform(df_test[['기초대사량']])\n",
    "\n",
    "\n",
    "# encoder\n",
    "encoder = LabelEncoder()\n",
    "df['키'] = encoder.fit_transform(df[['키']])\n",
    "df_test['키'] = encoder.transform(df_test[['키']])\n",
    "\n",
    "# get dummies\n",
    "df[['M', \"S\", \"XS\"]] = pd.get_dummies(df['체격'], dtype=float, drop_first = True)\n",
    "df[['동구', \"북구\", \"서구\"]] = pd.get_dummies(df['거주지역'], dtype=float, drop_first = True)\n",
    "\n",
    "df_test[['M', \"S\", \"XS\"]] = pd.get_dummies(df_test['체격'], dtype=float, drop_first = True)\n",
    "df_test[['동구', \"북구\", \"서구\"]] = pd.get_dummies(df_test['거주지역'], dtype=float, drop_first = True)\n",
    "\n",
    "\n",
    "y = df[['구분']]\n",
    "X = df[[\"일평균수면시간\", '일평균학습시간', '일평균스마트폰사용시간', '키', '몸무게', '기초대사량', 'M', 'S', 'XS', '동구', '북구', '서구']]\n",
    "\n",
    "X_test = df_test[[\"일평균수면시간\", '일평균학습시간', '일평균스마트폰사용시간', '키', '몸무게', '기초대사량', 'M', 'S', 'XS', '동구', '북구', '서구']]\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X, y)\n",
    "pred = rf.predict(X_test)\n",
    "\n",
    "submit_file = pd.DataFrame({'구분예측' : pred})\n",
    "submit_file.to_csv('submit.csv', index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기출문제 6회 문제 - 3유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.976190476190475\n",
      "0.07266054733847586\n"
     ]
    }
   ],
   "source": [
    "data1 = pd.DataFrame({'pain': ['무증상', '속쓰림', '무증상', '무증상', '조금아픔', '무증상', '조금아픔', '무증상', '조금아픔', '무증상', '아픔', '무증상', '조금아픔', '무증상', '아픔', '무증상', '속쓰림', '무증상', '아픔', '무증상']})\n",
    "# 1-1\n",
    "data1.value_counts(normalize = True)\n",
    "\n",
    "# 1-2\n",
    "import scipy.stats as ss\n",
    "val1 = data1.value_counts().to_list()\n",
    "val2 = [0.7 * 20, 0.1 * 20, 0.05 * 20, 0.15 * 20]\n",
    "statistic, p_value  = ss.chisquare(val1, val2)\n",
    "print(statistic)\n",
    "\n",
    "# 1-3\n",
    "print(p_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.17196604  0.00727564 -0.32294455]\n",
      "Intercept    72.418579\n",
      "Ozone         0.171966\n",
      "Solar         0.007276\n",
      "Wind         -0.322945\n",
      "dtype: float64\n",
      "Intercept    2.107000e-42\n",
      "Ozone        2.423506e-09\n",
      "Solar        3.454492e-01\n",
      "Wind         1.690987e-01\n",
      "dtype: float64\n",
      "        mean   mean_se  mean_ci_lower  mean_ci_upper  obs_ci_lower  \\\n",
      "0  78.826312  0.864464      77.112614      80.540011     65.171661   \n",
      "\n",
      "   obs_ci_upper  \n",
      "0     92.480964  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/data_6_3_2.csv')\n",
    "df = df.dropna(axis = 0)\n",
    "X = df[['Ozone', 'Solar', 'Wind']]\n",
    "y = df['Temp']\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lg = LinearRegression()\n",
    "lg.fit(X, y)\n",
    "print(lg.coef_)\n",
    "\n",
    "# 1\n",
    "# Answer : 0.17196604\n",
    "\n",
    "# 2\n",
    "from statsmodels.formula.api import ols\n",
    "formula = 'Temp ~ Ozone + Solar + Wind'\n",
    "lg = ols(formula, data = df).fit()\n",
    "print(lg.params)\n",
    "print(lg.pvalues)\n",
    "\n",
    "# 3. \n",
    "new_data = pd.DataFrame({\n",
    "    'Ozone': [45],\n",
    "    'Solar': [150],\n",
    "    'Wind': [7.5]\n",
    "})\n",
    "\n",
    "predictions = lg.get_prediction(new_data)\n",
    "print(predictions.summary_frame())\n",
    "# 78.826312\n",
    "# 77.112614      80.540011 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기출문제 5회 문제 - 1유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1-1\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/YoungjinBD/dataset/main/trash_bag.csv\", encoding = 'cp949')\n",
    "df1 = df[(df['용도'] == '음식물쓰레기') & (df['사용대상'] == '가정용')]\n",
    "df2 = df1[df1['2L가격']!=0]\n",
    "df2['2L가격'].mean()\n",
    "\n",
    "# Answer : 119\n",
    "\n",
    "# 1-2\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/YoungjinBD/dataset/main/BMI.csv\")\n",
    "df['BMI'] = df['Weight'] / (df['Height'] / 100) / (df['Height'] / 100) \n",
    "\n",
    "df[(18.5 <= df['BMI']) & (df['BMI']< 23)].shape[0] - df[(23 <= df['BMI']) & (df['BMI']< 25)].shape[0]\n",
    "\n",
    "# Answer : 28\n",
    "\n",
    "# 1-2\n",
    "df = pd.read_csv(\"https://raw.githubusercontent.com/YoungjinBD/dataset/main/students.csv\", encoding = 'cp949')\n",
    "df['순전입생'] = df['총 전입학생'] - df['총 전출학생']\n",
    "\n",
    "df.groupby('학교')['순전입생'].sum() # A\n",
    "df[df['학교'] == 'A']['전체학생 수'].sum()\n",
    "\n",
    "# Answer : 566\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기출문제 5회 문제 - 2유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X_test = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/used_car_X_test.csv')\n",
    "X_train = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/used_car_X_train.csv')\n",
    "y_train = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/used_car_y_train.csv')\n",
    "print(X_train.head())\n",
    "\n",
    "# 데이터 나누기\n",
    "# 범주형 데이터\n",
    "X_train_word = X_train[['model','transmission','fuelType']]\n",
    "X_test_word = X_test[['model','transmission','fuelType']]\n",
    "print(X_train_word)\n",
    "\n",
    "# 수치형 데이터\n",
    "X_train_num= X_train.drop(columns=['id','model','transmission','fuelType'])\n",
    "X_test_num= X_test.drop(columns=['id','model','transmission','fuelType'])\n",
    "print(X_train_num)\n",
    "# 데이터 스케일링\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# MinMax 스케일러 생성\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 선택한 특성에 MinMax 스케일러를 적용하고 데이터 변환\n",
    "X_train_num_scale = scaler.fit_transform(X_train_num)\n",
    "X_test_num_scale = scaler.transform(X_test_num)\n",
    "\n",
    "# 데이터 프레임 설정\n",
    "df_train_num = pd.DataFrame(X_train_num_scale , columns = X_train_num.columns)\n",
    "df_test_num = pd.DataFrame(X_test_num_scale , columns = X_test_num.columns)\n",
    "\n",
    "# 원핫 인코딩\n",
    "df_train_word = pd.get_dummies(X_train_word)\n",
    "df_test_word = pd.get_dummies(X_test_word)\n",
    "\n",
    "# 훈련 데이터프레임 컬럼 목록\n",
    "train_columns = set(df_train_word.columns)\n",
    "\n",
    "# 테스트 데이터프레임 컬럼 목록\n",
    "test_columns = set(df_test_word.columns)\n",
    "\n",
    "# 훈련 데이터에는 있지만 테스트 데이터에는 없는 컬럼 확인\n",
    "missing_in_test = train_columns - test_columns\n",
    "\n",
    "# 테스트 데이터에는 있지만 훈련 데이터에는 없는 컬럼 확인\n",
    "missing_in_train = test_columns - train_columns\n",
    "print(\"컬럼 목록 중 테스트 데이터에 없는 컬럼:\", missing_in_test)\n",
    "print(\"컬럼 목록 중 훈련 데이터에 없는 컬럼:\", missing_in_train)\n",
    "\n",
    "# 컬럼 목록 중 없는 컬럼의 값을 0으로 해서 채워줌\n",
    "df_test_word['model_ RS7'] = 0\n",
    "df_test_word['model_ S8'] = 0\n",
    "df_test_word['model_ A2'] = 0\n",
    "df_test_word['model_ S5'] = 0\n",
    "\n",
    "# 데이터 결합\n",
    "df_train = pd.concat([df_train_num, df_train_word], axis = 1)\n",
    "df_test = pd.concat([df_test_num, df_test_word], axis = 1)\n",
    "print(df_train)\n",
    "\n",
    "# 모델 학습\n",
    "from pandas.core.common import random_state\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "\n",
    "# 모델 생성\n",
    "model = xgb.XGBRegressor(random_state=77)\n",
    "\n",
    "# train , validation 데이터 설정\n",
    "X_train, X_val, y_train_t, y_val = train_test_split(df_train.values, y_train['price'].values, test_size=0.3)\n",
    "\n",
    "# 모델 학습\n",
    "model.fit(X_train, y_train_t)\n",
    "\n",
    "# vaidation 데이터로 성능 평가\n",
    "y_pred = model.predict(X_val)\n",
    "print(np.sqrt(mean_squared_error(y_val, y_pred)))\n",
    "\n",
    "# 예측\n",
    "y_pred = model.predict(df_test)\n",
    "df = pd.DataFrame(X_test['id'], columns=['id'])\n",
    "df['price'] = y_pred\n",
    "print(df.head())\n",
    "\n",
    "# CSV 파일 저장\n",
    "# df.to_csv('result.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기출문제 4회 문제 - 1유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n",
      "90\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "# 1-1\n",
    "import pandas as pd\n",
    "df = pd.Series([10, 11, 11.2, 13, 15.5, 18, 19.8, 20, 31, 33, 39.5, 42])\n",
    "Q1 = df.quantile(0.25)\n",
    "Q3 = df.quantile(0.75)\n",
    "print(int(abs(Q1-Q3)))\n",
    "\n",
    "# 1-2\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/facebook.csv')\n",
    "df['prop_positive'] = (df['num_loves'] + df['num_wows']) / df['num_reactions']\n",
    "print(len(df[(0.4 < df['prop_positive'])  & (df['prop_positive']< 0.5) & (df['status_type'] == 'video')]))\n",
    "\n",
    "# 1-3\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/netflix.csv')\n",
    "df['date_added'] = pd.to_datetime(df['date_added'])\n",
    "df['date_added_year'] = df['date_added'].dt.year\n",
    "df['date_added_month'] = df['date_added'].dt.month\n",
    "df['date_added_day'] = df['date_added'].dt.day\n",
    "\n",
    "df1 = df[(df['date_added_year'] == 2018) & (df['date_added_month'] == 1)]\n",
    "print(len(df1[df1['country'] == \"United Kingdom\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 기출문제 4회 문제 - 2유형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       ID  Gender Ever_Married  Age Graduated  Profession  Work_Experience  \\\n",
      "0  462809    Male           No   22        No  Healthcare              1.0   \n",
      "1  466315  Female          Yes   67       Yes    Engineer              1.0   \n",
      "2  461735    Male          Yes   67       Yes      Lawyer              0.0   \n",
      "3  461319    Male          Yes   56        No      Artist              0.0   \n",
      "4  460156    Male           No   32       Yes  Healthcare              1.0   \n",
      "\n",
      "  Spending_Score  Family_Size  \n",
      "0            Low          4.0  \n",
      "1            Low          1.0  \n",
      "2           High          2.0  \n",
      "3        Average          2.0  \n",
      "4            Low          3.0  \n",
      "       ID  Gender Ever_Married  Age Graduated  Profession  Work_Experience  \\\n",
      "0  458989  Female          Yes   36       Yes    Engineer              0.0   \n",
      "1  458994    Male          Yes   37       Yes  Healthcare              8.0   \n",
      "2  459000    Male          Yes   59        No   Executive             11.0   \n",
      "3  459003    Male          Yes   47       Yes      Doctor              0.0   \n",
      "4  459005    Male          Yes   61       Yes      Doctor              5.0   \n",
      "\n",
      "  Spending_Score  Family_Size  \n",
      "0            Low          1.0  \n",
      "1        Average          4.0  \n",
      "2           High          2.0  \n",
      "3           High          5.0  \n",
      "4            Low          3.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\pja07\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\pja07\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\pja07\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\pja07\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\pja07\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\pja07\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:114: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          ID Segmentation\n",
      "0     458989            B\n",
      "1     458994            C\n",
      "2     459000            C\n",
      "3     459003            C\n",
      "4     459005            A\n",
      "...      ...          ...\n",
      "2173  467950            A\n",
      "2174  467954            D\n",
      "2175  467958            B\n",
      "2176  467961            C\n",
      "2177  467968            D\n",
      "\n",
      "[2178 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "y_train = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/CS_Seg_y_train.csv')\n",
    "X_train = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/CS_Seg_X_train.csv')\n",
    "X_test = pd.read_csv('https://raw.githubusercontent.com/YoungjinBD/dataset/main/CS_Seg_X_test.csv')\n",
    "print(X_train.head())\n",
    "print(X_test.head())\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "encoder = LabelEncoder()\n",
    "X_train['Gender'] = encoder.fit_transform(X_train[['Gender']])\n",
    "X_test['Gender'] = encoder.fit_transform(X_test[['Gender']])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "X_train['Ever_Married'] = encoder.fit_transform(X_train[['Ever_Married']])\n",
    "X_test['Ever_Married'] = encoder.fit_transform(X_test[['Ever_Married']])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "X_train['Graduated'] = encoder.fit_transform(X_train[['Graduated']])\n",
    "X_test['Graduated'] = encoder.fit_transform(X_test[['Graduated']])\n",
    "\n",
    "# StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train['Age'] = scaler.fit_transform(X_train[['Age']])\n",
    "X_test['Age'] = scaler.transform(X_test[['Age']])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train['Work_Experience'] = scaler.fit_transform(X_train[['Work_Experience']])\n",
    "X_test['Work_Experience'] = scaler.transform(X_test[['Work_Experience']])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train['Family_Size'] = scaler.fit_transform(X_train[['Family_Size']])\n",
    "X_test['Family_Size'] = scaler.transform(X_test[['Family_Size']])\n",
    "\n",
    "# get_dummies\n",
    "X_train = pd.concat([X_train, pd.get_dummies(X_train['Profession'])], axis = 1)\n",
    "X_test = pd.concat([X_test, pd.get_dummies(X_test['Profession'])], axis = 1)\n",
    "\n",
    "X_train = pd.concat([X_train, pd.get_dummies(X_train['Spending_Score'])], axis = 1)\n",
    "X_test = pd.concat([X_test, pd.get_dummies(X_test['Spending_Score'])], axis = 1)\n",
    "\n",
    "\n",
    "X = X_train.drop(['ID', 'Profession', 'Spending_Score' ], axis = 1)\n",
    "id = X_test['ID']\n",
    "X_test = X_test.drop(['ID', 'Profession', 'Spending_Score' ], axis = 1)\n",
    "y_train2 = y_train['Segmentation']\n",
    "encoder = LabelEncoder()\n",
    "y_encoded = encoder.fit_transform(y_train2)\n",
    "\n",
    "# randomforest, xgboost\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(X, y_encoded)\n",
    "pred_xgb = xgb.predict(X_test)\n",
    "pred_xgb = encoder.inverse_transform(pred_xgb)\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X, y_encoded)\n",
    "pred_rf = rf.predict(X_test)\n",
    "pred_rf = encoder.inverse_transform(pred_rf)\n",
    "\n",
    "\n",
    "pred_rf = pd.DataFrame({\"ID\": id, 'Segmentation': pred_rf})\n",
    "print(pred_rf)\n",
    "\n",
    "pred_rf.to_csv(\"result.csv\", index = False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
